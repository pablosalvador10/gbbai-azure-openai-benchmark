{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory C:\\Users\\pablosal\\Desktop\\azure-openai-benchmark-pablosal does not exist.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the target directory (change yours)\n",
    "target_directory = r\"C:\\Users\\pablosal\\Desktop\\azure-openai-benchmark\"\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(target_directory):\n",
    "    # Change the current working directory\n",
    "    os.chdir(target_directory)\n",
    "    print(f\"Directory changed to {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"Directory {target_directory} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Now you can access the environment variables using os.getenv\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_ID = os.getenv(\"AZURE_AOAI_DEPLOYMENT_NAME\")\n",
    "DEPLOYMENT_VERSION = os.getenv(\"AZURE_AOAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Create a custom logger\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set the level of this logger. This level acts as a threshold. \n",
    "# Any message logged at this level, or higher, will be passed to this logger's handlers.\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Create handlers\n",
    "c_handler = logging.StreamHandler()\n",
    "c_handler.setLevel(logging.DEBUG)\n",
    "c_format = logging.Formatter('%(name)s - %(levelname)s - %(message)s')\n",
    "c_handler.setFormatter(c_format)\n",
    "logger.addHandler(c_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Sample Runs\n",
    "\n",
    "During a test run, the system periodically outputs statistics every 60 seconds to the standard output (stdout), while logs are directed to the standard error output (stderr). Please note that some metrics may not be immediately visible due to insufficient data.\n",
    "\n",
    "Initiate a load test at a rate of 60 Requests Per Minute (RPM) with an exponential back-off retry strategy. This strategy helps to efficiently handle potential API rate limit issues by gradually increasing the wait time between retries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark.client import BenchmarkingTool\n",
    "\n",
    "# Create a client\n",
    "benchmarking_client = BenchmarkingTool(\n",
    "    model=\"gpt-4-1106-pagyo\",\n",
    "    region=\"swedencentral\",\n",
    "    endpoint=AZURE_OPENAI_ENDPOINT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-19 23:09:08,635 - micro - MainProcess - INFO     Initiating load generation tests with ID 5a9e. Log output will be directed to: logs/gpt-4-1106-pagyo/swedencentral/log_runs/2024-03-19/23-09-08/5a9e.log (client.py:run_tests:208)\n",
      "2024-03-19 23:09:08,636 - micro - MainProcess - INFO     Executing command: python -m benchmark.bench load --api-version 2023-05-15 --api-key-env OPENAI_API_KEY --clients 10 --duration 180 --run-end-condition-mode or --rate 5 --aggregation-window 60 --context-generation-method generate --shape-profile custom --context-tokens 1000 --max-tokens 500 --prevent-server-caching True --completions 1 --output-format human --log-save-dir logs/ --retry none --deployment gpt-4-1106-pagyo https://gbb-ea-openai-swedencentral-01.openai.azure.com/ (client.py:run_tests:209)\n",
      "2024-03-19 23:13:10,874 - micro - MainProcess - INFO     Combining logs. Results will be saved to: logs/gpt-4-1106-pagyo/swedencentral/results/2024-03-19/23-09-08/5a9e.csv (client.py:run_tests:226)\n",
      "2024-03-19 23:13:11,656 - micro - MainProcess - INFO     Load generation tests have completed. Please refer to logs/gpt-4-1106-pagyo/swedencentral/log_runs/2024-03-19/23-09-08/5a9e.log for the detailed logs. (client.py:run_tests:229)\n"
     ]
    }
   ],
   "source": [
    "benchmarking_client.run_tests(deployment=\"gpt-4-1106-pagyo\",\n",
    "                              rate=5,\n",
    "                              duration=180,\n",
    "                              shape_profile=\"custom\",\n",
    "                              clients=10,\n",
    "                              context_tokens=1000,\n",
    "                              max_tokens=500,\n",
    "                              prevent_server_caching=True,\n",
    "                              log_save_dir=\"logs/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptu-benchmarking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
