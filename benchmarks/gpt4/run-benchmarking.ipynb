{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š Prerequisites\n",
    "\n",
    "Ensure that your Azure Services are properly set up, your Conda environment is created, and your environment variables are configured as per the instructions in the [SETTINGS.md](SETTINGS.md) file.\n",
    "\n",
    "## ðŸ“‹ Table of Contents\n",
    "\n",
    "This notebook assists in conducting a comprehensive performance assessment for Azure OpenAI endpoints, focusing on the operational efficiency of the model in processing requests. The following sections are covered:\n",
    "\n",
    "1. [**Latency Testing**](#latency-testing): This section explores how to conduct latency tests on Azure OpenAI endpoints. Latency measures the response time for a request, assessing how quickly the model responds to a specific request.\n",
    "\n",
    "2. [**Throughput Testing**](#throughput-testing): This part details the steps to perform throughput tests on Azure OpenAI endpoints. Throughput evaluates the number of requests the model can handle in a given time frame, providing an understanding of the model's capacity and efficiency.\n",
    "\n",
    "3. [**Analyzing Test Results**](#analyzing-test-results): This section provides guidance on how to analyze the results from the latency and throughput tests, helping you understand the performance metrics and their implications on the operational efficiency of your model.\n",
    "\n",
    "For additional information, refer to the following resources:\n",
    "- [Azure OpenAI API Documentation](https://learn.microsoft.com/en-us/azure/ai-services/openai/reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory changed to C:\\Users\\pablosal\\Desktop\\gbbai-azure-openai-benchmark\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the target directory\n",
    "TARGET_DIRECTORY = \"C:\\\\Users\\\\pablosal\\\\Desktop\\\\gbbai-azure-openai-benchmark\"\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "if current_directory != TARGET_DIRECTORY:\n",
    "    # Go up one directory from the current working directory\n",
    "    PARENT_DIRECTORY = os.path.join(current_directory, '..', '..')\n",
    "    PARENT_DIRECTORY = os.path.realpath(PARENT_DIRECTORY)\n",
    "\n",
    "    # Change the current working directory to the parent directory\n",
    "    os.chdir(PARENT_DIRECTORY)\n",
    "    print(f\"Directory changed to {os.getcwd()}\")\n",
    "else:\n",
    "    print(\"Current directory is already the target directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP \n",
    "MODEL = \"gpt-4-0613-ptu\"\n",
    "REGION = \"swedencentral\"\n",
    "OAZURE_OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY_SWEEDENCENTRAL_GPT4_PTU\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT_SWEEDENCENTRAL_GPT4_PTU\")\n",
    "AZURE_OPENAI_API_VERSION = \"2024-02-15-preview\"\n",
    "\n",
    "FILENAME = f\"benchmarks/gpt4/{REGION}/{MODEL}/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Latency Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.performance.aoaihelpers.latencytest import (\n",
    "    AzureOpenAIBenchmarkStreaming,\n",
    "    AzureOpenAIBenchmarkNonStreaming,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the deployment names and tokens\n",
    "deployment_names = [MODEL]\n",
    "max_tokens_list = [100, 500, 700, 800]\n",
    "num_iterations = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 22:58:48,872 - micro - MainProcess - INFO     CPU usage: 16.1% (utils.py:log_system_info:200)\n",
      "2024-05-13 22:58:48,900 - micro - MainProcess - INFO     RAM usage: 87.3% (utils.py:log_system_info:202)\n",
      "2024-05-13 22:58:49,456 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100\n",
      "2024-05-13 22:58:49,489 - micro - MainProcess - INFO     CPU usage: 13.1% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 13.1%\n",
      "2024-05-13 22:58:49,505 - micro - MainProcess - INFO     RAM usage: 87.3% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 87.3%\n",
      "2024-05-13 22:58:49,616 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500\n",
      "2024-05-13 22:58:49,619 - micro - MainProcess - INFO     CPU usage: 4.2% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 4.2%\n",
      "2024-05-13 22:58:49,633 - micro - MainProcess - INFO     RAM usage: 87.3% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 87.3%\n",
      "2024-05-13 22:58:49,742 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700\n",
      "2024-05-13 22:58:49,745 - micro - MainProcess - INFO     CPU usage: 10.3% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 10.3%\n",
      "2024-05-13 22:58:49,763 - micro - MainProcess - INFO     RAM usage: 87.3% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 87.3%\n",
      "2024-05-13 22:58:49,901 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800\n",
      "2024-05-13 22:58:54,320 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 22:59:01,287 - micro - MainProcess - INFO     Succesful Run - Time taken: 4.86 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 4.86 seconds.\n",
      "2024-05-13 22:59:02,298 - micro - MainProcess - INFO     CPU usage: 14.1% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 14.1%\n",
      "2024-05-13 22:59:02,311 - micro - MainProcess - INFO     RAM usage: 90.7% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 90.7%\n",
      "2024-05-13 22:59:02,443 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100\n",
      "2024-05-13 22:59:04,971 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 22:59:04,974 - micro - MainProcess - INFO     Succesful Run - Time taken: 15.23 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 15.23 seconds.\n",
      "2024-05-13 22:59:05,983 - micro - MainProcess - INFO     CPU usage: 12.2% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 12.2%\n",
      "2024-05-13 22:59:05,997 - micro - MainProcess - INFO     RAM usage: 87.7% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 87.7%\n",
      "2024-05-13 22:59:06,154 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500\n",
      "2024-05-13 22:59:06,159 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 22:59:06,161 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.71 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 3.71 seconds.\n",
      "2024-05-13 22:59:07,174 - micro - MainProcess - INFO     CPU usage: 10.9% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 10.9%\n",
      "2024-05-13 22:59:07,189 - micro - MainProcess - INFO     RAM usage: 87.7% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 87.7%\n",
      "2024-05-13 22:59:07,302 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100\n",
      "2024-05-13 22:59:10,383 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 22:59:10,388 - micro - MainProcess - INFO     Succesful Run - Time taken: 20.35 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 20.35 seconds.\n",
      "2024-05-13 22:59:10,806 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 22:59:10,808 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.50 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 3.50 seconds.\n",
      "2024-05-13 22:59:11,403 - micro - MainProcess - INFO     CPU usage: 13.5% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 13.5%\n",
      "2024-05-13 22:59:11,416 - micro - MainProcess - INFO     RAM usage: 88.3% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 88.3%\n",
      "2024-05-13 22:59:11,527 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800\n",
      "2024-05-13 22:59:11,823 - micro - MainProcess - INFO     CPU usage: 11.4% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 11.4%\n",
      "2024-05-13 22:59:11,834 - micro - MainProcess - INFO     RAM usage: 89.5% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.5%\n",
      "2024-05-13 22:59:11,937 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100\n",
      "2024-05-13 22:59:11,943 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 22:59:11,945 - micro - MainProcess - INFO     Succesful Run - Time taken: 21.96 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 21.96 seconds.\n",
      "2024-05-13 22:59:12,959 - micro - MainProcess - INFO     CPU usage: 27.8% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 27.8%\n",
      "2024-05-13 22:59:12,971 - micro - MainProcess - INFO     RAM usage: 88.2% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 88.2%\n",
      "2024-05-13 22:59:13,152 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700\n",
      "2024-05-13 22:59:15,430 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 22:59:15,431 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.49 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 3.49 seconds.\n",
      "2024-05-13 22:59:16,437 - micro - MainProcess - INFO     CPU usage: 17.0% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 17.0%\n",
      "2024-05-13 22:59:16,450 - micro - MainProcess - INFO     RAM usage: 87.8% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 87.8%\n",
      "2024-05-13 22:59:16,584 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100\n",
      "2024-05-13 22:59:20,083 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 22:59:20,086 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.49 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 3.49 seconds.\n",
      "2024-05-13 22:59:21,103 - micro - MainProcess - INFO     CPU usage: 24.1% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 24.1%\n",
      "2024-05-13 22:59:21,116 - micro - MainProcess - INFO     RAM usage: 88.1% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 88.1%\n",
      "2024-05-13 22:59:21,222 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100\n",
      "2024-05-13 22:59:21,424 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 22:59:21,428 - micro - MainProcess - INFO     Succesful Run - Time taken: 15.14 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 15.14 seconds.\n",
      "2024-05-13 22:59:22,435 - micro - MainProcess - INFO     CPU usage: 9.7% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 9.7%\n",
      "2024-05-13 22:59:22,448 - micro - MainProcess - INFO     RAM usage: 92.3% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 92.3%\n",
      "2024-05-13 22:59:22,578 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500\n",
      "2024-05-13 22:59:24,694 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 22:59:24,697 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.47 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 3.47 seconds.\n",
      "2024-05-13 22:59:25,715 - micro - MainProcess - INFO     CPU usage: 22.0% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 22.0%\n",
      "2024-05-13 22:59:25,728 - micro - MainProcess - INFO     RAM usage: 89.1% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.1%\n",
      "2024-05-13 22:59:25,847 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100\n",
      "2024-05-13 22:59:29,351 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 22:59:29,354 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.50 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 3.50 seconds.\n",
      "2024-05-13 22:59:30,370 - micro - MainProcess - INFO     CPU usage: 11.5% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 11.5%\n",
      "2024-05-13 22:59:30,384 - micro - MainProcess - INFO     RAM usage: 89.4% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.4%\n",
      "2024-05-13 22:59:30,515 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100\n",
      "2024-05-13 22:59:30,928 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 22:59:30,930 - micro - MainProcess - INFO     Succesful Run - Time taken: 19.27 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 19.27 seconds.\n",
      "2024-05-13 22:59:31,953 - micro - MainProcess - INFO     CPU usage: 10.0% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 10.0%\n",
      "2024-05-13 22:59:31,968 - micro - MainProcess - INFO     RAM usage: 89.5% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.5%\n",
      "2024-05-13 22:59:32,140 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800\n",
      "2024-05-13 22:59:32,487 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 22:59:32,489 - micro - MainProcess - INFO     Succesful Run - Time taken: 19.20 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 19.20 seconds.\n",
      "2024-05-13 22:59:33,518 - micro - MainProcess - INFO     CPU usage: 15.0% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 15.0%\n",
      "2024-05-13 22:59:33,529 - micro - MainProcess - INFO     RAM usage: 91.4% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 91.4%\n",
      "2024-05-13 22:59:33,627 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700\n",
      "2024-05-13 22:59:34,135 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 22:59:34,139 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.62 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 3.62 seconds.\n",
      "2024-05-13 22:59:35,142 - micro - MainProcess - INFO     CPU usage: 16.9% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 16.9%\n",
      "2024-05-13 22:59:35,153 - micro - MainProcess - INFO     RAM usage: 92.7% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 92.7%\n",
      "2024-05-13 22:59:35,298 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100\n",
      "2024-05-13 22:59:38,115 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 22:59:38,117 - micro - MainProcess - INFO     Succesful Run - Time taken: 15.41 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 15.41 seconds.\n",
      "2024-05-13 22:59:38,778 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 22:59:38,781 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.47 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 3.47 seconds.\n",
      "2024-05-13 22:59:39,116 - micro - MainProcess - INFO     CPU usage: 16.0% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 16.0%\n",
      "2024-05-13 22:59:39,130 - micro - MainProcess - INFO     RAM usage: 89.5% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.5%\n",
      "2024-05-13 22:59:39,265 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500\n",
      "2024-05-13 22:59:39,798 - micro - MainProcess - INFO     CPU usage: 14.5% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 14.5%\n",
      "2024-05-13 22:59:39,811 - micro - MainProcess - INFO     RAM usage: 89.1% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.1%\n",
      "2024-05-13 22:59:39,937 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100\n",
      "2024-05-13 22:59:43,498 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 22:59:43,500 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.56 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 3.56 seconds.\n",
      "2024-05-13 22:59:44,516 - micro - MainProcess - INFO     CPU usage: 15.7% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 15.7%\n",
      "2024-05-13 22:59:44,530 - micro - MainProcess - INFO     RAM usage: 89.3% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.3%\n",
      "2024-05-13 22:59:44,662 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100\n",
      "2024-05-13 22:59:48,292 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 22:59:48,295 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.63 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 3.63 seconds.\n",
      "2024-05-13 22:59:49,311 - micro - MainProcess - INFO     CPU usage: 8.9% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 8.9%\n",
      "2024-05-13 22:59:49,325 - micro - MainProcess - INFO     RAM usage: 88.8% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 88.8%\n",
      "2024-05-13 22:59:49,498 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100\n",
      "2024-05-13 22:59:51,688 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 22:59:51,839 - micro - MainProcess - INFO     Succesful Run - Time taken: 19.42 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 19.42 seconds.\n",
      "2024-05-13 22:59:52,665 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 22:59:52,665 - micro - MainProcess - INFO     Succesful Run - Time taken: 18.91 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 18.91 seconds.\n",
      "2024-05-13 22:59:52,998 - micro - MainProcess - INFO     CPU usage: 11.3% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 11.3%\n",
      "2024-05-13 22:59:53,016 - micro - MainProcess - INFO     RAM usage: 88.7% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 88.7%\n",
      "2024-05-13 22:59:53,310 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800\n",
      "2024-05-13 22:59:53,316 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 22:59:53,320 - micro - MainProcess - INFO     Succesful Run - Time taken: 14.05 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 14.05 seconds.\n",
      "2024-05-13 22:59:53,323 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 22:59:53,326 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.83 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 3.83 seconds.\n",
      "2024-05-13 22:59:53,677 - micro - MainProcess - INFO     CPU usage: 13.8% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 13.8%\n",
      "2024-05-13 22:59:53,693 - micro - MainProcess - INFO     RAM usage: 88.7% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 88.7%\n",
      "2024-05-13 22:59:53,915 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700\n",
      "2024-05-13 22:59:54,335 - micro - MainProcess - INFO     CPU usage: 15.4% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 15.4%\n",
      "2024-05-13 22:59:54,348 - micro - MainProcess - INFO     RAM usage: 88.7% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 88.7%\n",
      "2024-05-13 22:59:54,548 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500\n",
      "2024-05-13 22:59:54,548 - micro - MainProcess - INFO     CPU usage: 21.0% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 21.0%\n",
      "2024-05-13 22:59:54,564 - micro - MainProcess - INFO     RAM usage: 88.6% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 88.6%\n",
      "2024-05-13 22:59:54,759 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100\n",
      "2024-05-13 22:59:58,315 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 22:59:58,315 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.56 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 3.56 seconds.\n",
      "2024-05-13 22:59:59,332 - micro - MainProcess - INFO     CPU usage: 17.2% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 17.2%\n",
      "2024-05-13 22:59:59,348 - micro - MainProcess - INFO     RAM usage: 90.4% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 90.4%\n",
      "2024-05-13 22:59:59,581 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100\n",
      "2024-05-13 23:00:03,081 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:00:03,086 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.50 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 3.50 seconds.\n",
      "2024-05-13 23:00:04,093 - micro - MainProcess - INFO     CPU usage: 22.2% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 22.2%\n",
      "2024-05-13 23:00:04,106 - micro - MainProcess - INFO     RAM usage: 89.3% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.3%\n",
      "2024-05-13 23:00:04,285 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100\n",
      "2024-05-13 23:00:07,981 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:00:08,064 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.68 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 3.68 seconds.\n",
      "2024-05-13 23:00:08,832 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:00:08,832 - micro - MainProcess - INFO     Succesful Run - Time taken: 14.15 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 14.15 seconds.\n",
      "2024-05-13 23:00:09,145 - micro - MainProcess - INFO     CPU usage: 19.3% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 19.3%\n",
      "2024-05-13 23:00:09,273 - micro - MainProcess - INFO     RAM usage: 89.0% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.0%\n",
      "2024-05-13 23:00:10,209 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100\n",
      "2024-05-13 23:00:10,216 - micro - MainProcess - INFO     CPU usage: 18.5% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 18.5%\n",
      "2024-05-13 23:00:10,236 - micro - MainProcess - INFO     RAM usage: 89.2% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.2%\n",
      "2024-05-13 23:00:10,424 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500\n",
      "2024-05-13 23:00:11,526 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:00:11,532 - micro - MainProcess - INFO     Succesful Run - Time taken: 18.09 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 18.09 seconds.\n",
      "2024-05-13 23:00:12,542 - micro - MainProcess - INFO     CPU usage: 23.5% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 23.5%\n",
      "2024-05-13 23:00:12,568 - micro - MainProcess - INFO     RAM usage: 89.7% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.7%\n",
      "2024-05-13 23:00:12,756 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800\n",
      "2024-05-13 23:00:13,914 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:00:13,914 - micro - MainProcess - INFO     Succesful Run - Time taken: 19.87 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 19.87 seconds.\n",
      "2024-05-13 23:00:14,403 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:00:14,403 - micro - MainProcess - INFO     Succesful Run - Time taken: 4.19 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 4.19 seconds.\n",
      "2024-05-13 23:00:14,945 - micro - MainProcess - INFO     CPU usage: 37.8% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 37.8%\n",
      "2024-05-13 23:00:14,962 - micro - MainProcess - INFO     RAM usage: 90.2% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 90.2%\n",
      "2024-05-13 23:00:15,099 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700\n",
      "2024-05-13 23:00:15,433 - micro - MainProcess - INFO     CPU usage: 19.2% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 19.2%\n",
      "2024-05-13 23:00:15,449 - micro - MainProcess - INFO     RAM usage: 93.2% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 93.2%\n",
      "2024-05-13 23:00:15,598 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100\n",
      "2024-05-13 23:00:19,081 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:00:19,081 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.47 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 3.47 seconds.\n",
      "2024-05-13 23:00:20,094 - micro - MainProcess - INFO     CPU usage: 23.8% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 23.8%\n",
      "2024-05-13 23:00:20,115 - micro - MainProcess - INFO     RAM usage: 89.2% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.2%\n",
      "2024-05-13 23:00:20,320 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100\n",
      "2024-05-13 23:00:23,852 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:00:23,852 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.53 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 3.53 seconds.\n",
      "2024-05-13 23:00:24,841 - micro - MainProcess - INFO     CPU usage: 21.6% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 21.6%\n",
      "2024-05-13 23:00:24,855 - micro - MainProcess - INFO     RAM usage: 89.2% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.2%\n",
      "2024-05-13 23:00:25,848 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100\n",
      "2024-05-13 23:00:25,857 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:00:25,865 - micro - MainProcess - INFO     Succesful Run - Time taken: 14.40 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 14.40 seconds.\n",
      "2024-05-13 23:00:26,889 - micro - MainProcess - INFO     CPU usage: 17.8% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 17.8%\n",
      "2024-05-13 23:00:26,898 - micro - MainProcess - INFO     RAM usage: 89.4% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.4%\n",
      "2024-05-13 23:00:27,081 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500\n",
      "2024-05-13 23:00:29,571 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:00:29,571 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.71 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 3.71 seconds.\n",
      "2024-05-13 23:00:30,591 - micro - MainProcess - INFO     CPU usage: 15.2% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 15.2%\n",
      "2024-05-13 23:00:30,607 - micro - MainProcess - INFO     RAM usage: 89.4% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.4%\n",
      "2024-05-13 23:00:30,814 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100\n",
      "2024-05-13 23:00:31,215 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:00:31,229 - micro - MainProcess - INFO     Succesful Run - Time taken: 18.33 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 18.33 seconds.\n",
      "2024-05-13 23:00:32,259 - micro - MainProcess - INFO     CPU usage: 29.8% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 29.8%\n",
      "2024-05-13 23:00:32,275 - micro - MainProcess - INFO     RAM usage: 92.3% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 92.3%\n",
      "2024-05-13 23:00:32,448 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800\n",
      "2024-05-13 23:00:34,498 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:00:34,502 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.67 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 3.67 seconds.\n",
      "2024-05-13 23:00:34,948 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:00:34,948 - micro - MainProcess - INFO     Succesful Run - Time taken: 19.70 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 19.70 seconds.\n",
      "2024-05-13 23:00:35,519 - micro - MainProcess - INFO     CPU usage: 28.5% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 28.5%\n",
      "2024-05-13 23:00:35,531 - micro - MainProcess - INFO     RAM usage: 89.6% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.6%\n",
      "2024-05-13 23:00:35,731 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100\n",
      "2024-05-13 23:00:35,953 - micro - MainProcess - INFO     CPU usage: 33.2% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 33.2%\n",
      "2024-05-13 23:00:35,969 - micro - MainProcess - INFO     RAM usage: 89.6% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.6%\n",
      "2024-05-13 23:00:36,232 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700\n",
      "2024-05-13 23:00:39,720 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:00:39,720 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.97 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 3.97 seconds.\n",
      "2024-05-13 23:00:40,743 - micro - MainProcess - INFO     CPU usage: 21.4% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 21.4%\n",
      "2024-05-13 23:00:40,807 - micro - MainProcess - INFO     RAM usage: 89.6% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.6%\n",
      "2024-05-13 23:00:41,012 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100\n",
      "2024-05-13 23:00:41,615 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:00:41,615 - micro - MainProcess - INFO     Succesful Run - Time taken: 14.41 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 14.41 seconds.\n",
      "2024-05-13 23:00:42,635 - micro - MainProcess - INFO     CPU usage: 32.0% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 32.0%\n",
      "2024-05-13 23:00:42,651 - micro - MainProcess - INFO     RAM usage: 89.6% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.6%\n",
      "2024-05-13 23:00:42,848 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500\n",
      "2024-05-13 23:00:44,648 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:00:44,648 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.63 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 3.63 seconds.\n",
      "2024-05-13 23:00:45,657 - micro - MainProcess - INFO     CPU usage: 18.7% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 18.7%\n",
      "2024-05-13 23:00:45,673 - micro - MainProcess - INFO     RAM usage: 89.9% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.9%\n",
      "2024-05-13 23:00:45,831 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100\n",
      "2024-05-13 23:00:49,372 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:00:49,372 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.54 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 3.54 seconds.\n",
      "2024-05-13 23:00:50,390 - micro - MainProcess - INFO     CPU usage: 17.1% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 17.1%\n",
      "2024-05-13 23:00:50,406 - micro - MainProcess - INFO     RAM usage: 90.0% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 90.0%\n",
      "2024-05-13 23:00:50,565 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100\n",
      "2024-05-13 23:00:52,248 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:00:52,248 - micro - MainProcess - INFO     Succesful Run - Time taken: 19.66 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 19.66 seconds.\n",
      "2024-05-13 23:00:53,266 - micro - MainProcess - INFO     CPU usage: 17.1% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 17.1%\n",
      "2024-05-13 23:00:53,284 - micro - MainProcess - INFO     RAM usage: 91.1% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 91.1%\n",
      "2024-05-13 23:00:53,465 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800\n",
      "2024-05-13 23:00:54,385 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:00:54,387 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.81 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 3.81 seconds.\n",
      "2024-05-13 23:00:55,231 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:00:55,241 - micro - MainProcess - INFO     Succesful Run - Time taken: 18.87 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 18.87 seconds.\n",
      "2024-05-13 23:00:55,401 - micro - MainProcess - INFO     CPU usage: 18.8% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 18.8%\n",
      "2024-05-13 23:00:55,417 - micro - MainProcess - INFO     RAM usage: 89.4% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.4%\n",
      "2024-05-13 23:00:55,598 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 100\n",
      "2024-05-13 23:00:56,315 - micro - MainProcess - INFO     CPU usage: 16.6% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 16.6%\n",
      "2024-05-13 23:00:56,331 - micro - MainProcess - INFO     RAM usage: 89.5% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.5%\n",
      "2024-05-13 23:00:56,932 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700\n",
      "2024-05-13 23:00:56,955 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:00:56,955 - micro - MainProcess - INFO     Succesful Run - Time taken: 14.10 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 14.10 seconds.\n",
      "2024-05-13 23:00:57,986 - micro - MainProcess - INFO     CPU usage: 16.8% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 16.8%\n",
      "2024-05-13 23:00:58,002 - micro - MainProcess - INFO     RAM usage: 89.5% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.5%\n",
      "2024-05-13 23:00:58,898 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500\n",
      "2024-05-13 23:00:59,106 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:00:59,115 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.50 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 3.50 seconds.\n",
      "2024-05-13 23:01:08,948 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:01:08,953 - micro - MainProcess - INFO     Succesful Run - Time taken: 15.34 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 15.34 seconds.\n",
      "2024-05-13 23:01:09,954 - micro - MainProcess - INFO     CPU usage: 18.4% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 18.4%\n",
      "2024-05-13 23:01:09,981 - micro - MainProcess - INFO     RAM usage: 89.5% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.5%\n",
      "2024-05-13 23:01:10,148 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800\n",
      "2024-05-13 23:01:12,823 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:01:12,823 - micro - MainProcess - INFO     Succesful Run - Time taken: 13.80 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 13.80 seconds.\n",
      "2024-05-13 23:01:13,831 - micro - MainProcess - INFO     CPU usage: 19.3% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 19.3%\n",
      "2024-05-13 23:01:13,848 - micro - MainProcess - INFO     RAM usage: 89.5% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.5%\n",
      "2024-05-13 23:01:14,055 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500\n",
      "2024-05-13 23:01:19,081 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:01:19,081 - micro - MainProcess - INFO     Succesful Run - Time taken: 22.00 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 22.00 seconds.\n",
      "2024-05-13 23:01:20,098 - micro - MainProcess - INFO     CPU usage: 16.1% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 16.1%\n",
      "2024-05-13 23:01:20,114 - micro - MainProcess - INFO     RAM usage: 89.7% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.7%\n",
      "2024-05-13 23:01:20,315 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700\n",
      "2024-05-13 23:01:28,802 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:01:28,812 - micro - MainProcess - INFO     Succesful Run - Time taken: 14.61 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 14.61 seconds.\n",
      "2024-05-13 23:01:29,819 - micro - MainProcess - INFO     CPU usage: 15.5% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 15.5%\n",
      "2024-05-13 23:01:29,835 - micro - MainProcess - INFO     RAM usage: 89.4% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.4%\n",
      "2024-05-13 23:01:30,165 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500\n",
      "2024-05-13 23:01:31,167 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:01:31,167 - micro - MainProcess - INFO     Succesful Run - Time taken: 20.89 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 20.89 seconds.\n",
      "2024-05-13 23:01:32,176 - micro - MainProcess - INFO     CPU usage: 29.5% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 29.5%\n",
      "2024-05-13 23:01:32,192 - micro - MainProcess - INFO     RAM usage: 89.6% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.6%\n",
      "2024-05-13 23:01:32,400 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800\n",
      "2024-05-13 23:01:39,260 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:01:39,265 - micro - MainProcess - INFO     Succesful Run - Time taken: 18.82 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 18.82 seconds.\n",
      "2024-05-13 23:01:40,274 - micro - MainProcess - INFO     CPU usage: 18.7% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 18.7%\n",
      "2024-05-13 23:01:40,290 - micro - MainProcess - INFO     RAM usage: 89.5% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.5%\n",
      "2024-05-13 23:01:40,515 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700\n",
      "2024-05-13 23:01:44,282 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:01:44,282 - micro - MainProcess - INFO     Succesful Run - Time taken: 13.98 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 13.98 seconds.\n",
      "2024-05-13 23:01:45,300 - micro - MainProcess - INFO     CPU usage: 15.8% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 15.8%\n",
      "2024-05-13 23:01:45,316 - micro - MainProcess - INFO     RAM usage: 90.9% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 90.9%\n",
      "2024-05-13 23:01:45,482 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500\n",
      "2024-05-13 23:01:54,598 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:01:54,598 - micro - MainProcess - INFO     Succesful Run - Time taken: 22.07 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 22.07 seconds.\n",
      "2024-05-13 23:01:55,604 - micro - MainProcess - INFO     CPU usage: 14.6% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 14.6%\n",
      "2024-05-13 23:01:55,620 - micro - MainProcess - INFO     RAM usage: 89.4% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.4%\n",
      "2024-05-13 23:01:55,865 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800\n",
      "2024-05-13 23:01:59,431 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:01:59,431 - micro - MainProcess - INFO     Succesful Run - Time taken: 13.82 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 13.82 seconds.\n",
      "2024-05-13 23:02:00,098 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:02:00,114 - micro - MainProcess - INFO     Succesful Run - Time taken: 19.46 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 19.46 seconds.\n",
      "2024-05-13 23:02:00,450 - micro - MainProcess - INFO     CPU usage: 16.5% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 16.5%\n",
      "2024-05-13 23:02:00,466 - micro - MainProcess - INFO     RAM usage: 89.5% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.5%\n",
      "2024-05-13 23:02:00,681 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500\n",
      "2024-05-13 23:02:01,109 - micro - MainProcess - INFO     CPU usage: 44.4% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 44.4%\n",
      "2024-05-13 23:02:01,155 - micro - MainProcess - INFO     RAM usage: 89.9% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.9%\n",
      "2024-05-13 23:02:01,320 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700\n",
      "2024-05-13 23:02:14,848 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:02:14,848 - micro - MainProcess - INFO     Succesful Run - Time taken: 14.03 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 14.03 seconds.\n",
      "2024-05-13 23:02:15,870 - micro - MainProcess - INFO     CPU usage: 14.8% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 14.8%\n",
      "2024-05-13 23:02:15,886 - micro - MainProcess - INFO     RAM usage: 88.7% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 88.7%\n",
      "2024-05-13 23:02:16,063 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500\n",
      "2024-05-13 23:02:16,065 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:02:16,065 - micro - MainProcess - INFO     Succesful Run - Time taken: 19.97 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 19.97 seconds.\n",
      "2024-05-13 23:02:17,068 - micro - MainProcess - INFO     CPU usage: 26.5% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 26.5%\n",
      "2024-05-13 23:02:17,084 - micro - MainProcess - INFO     RAM usage: 88.1% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 88.1%\n",
      "2024-05-13 23:02:17,231 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800\n",
      "2024-05-13 23:02:19,310 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:02:19,314 - micro - MainProcess - INFO     Succesful Run - Time taken: 17.86 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 17.86 seconds.\n",
      "2024-05-13 23:02:20,322 - micro - MainProcess - INFO     CPU usage: 42.5% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 42.5%\n",
      "2024-05-13 23:02:20,338 - micro - MainProcess - INFO     RAM usage: 87.9% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 87.9%\n",
      "2024-05-13 23:02:20,531 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700\n",
      "2024-05-13 23:02:32,748 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:02:32,748 - micro - MainProcess - INFO     Succesful Run - Time taken: 16.55 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 16.55 seconds.\n",
      "2024-05-13 23:02:33,772 - micro - MainProcess - INFO     CPU usage: 26.9% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 26.9%\n",
      "2024-05-13 23:02:33,788 - micro - MainProcess - INFO     RAM usage: 86.4% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 86.4%\n",
      "2024-05-13 23:02:34,019 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500\n",
      "2024-05-13 23:02:37,981 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:02:37,993 - micro - MainProcess - INFO     Succesful Run - Time taken: 20.61 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 20.61 seconds.\n",
      "2024-05-13 23:02:39,015 - micro - MainProcess - INFO     CPU usage: 19.3% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 19.3%\n",
      "2024-05-13 23:02:39,033 - micro - MainProcess - INFO     RAM usage: 86.4% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 86.4%\n",
      "2024-05-13 23:02:39,819 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800\n",
      "2024-05-13 23:02:40,465 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:02:40,475 - micro - MainProcess - INFO     Succesful Run - Time taken: 19.80 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 19.80 seconds.\n",
      "2024-05-13 23:02:41,489 - micro - MainProcess - INFO     CPU usage: 15.7% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 15.7%\n",
      "2024-05-13 23:02:41,500 - micro - MainProcess - INFO     RAM usage: 86.4% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 86.4%\n",
      "2024-05-13 23:02:41,724 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700\n",
      "2024-05-13 23:02:48,482 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:02:48,482 - micro - MainProcess - INFO     Succesful Run - Time taken: 14.32 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 14.32 seconds.\n",
      "2024-05-13 23:02:49,501 - micro - MainProcess - INFO     CPU usage: 15.4% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 15.4%\n",
      "2024-05-13 23:02:49,517 - micro - MainProcess - INFO     RAM usage: 86.5% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 86.5%\n",
      "2024-05-13 23:02:49,820 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500\n",
      "2024-05-13 23:02:59,901 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:02:59,917 - micro - MainProcess - INFO     Succesful Run - Time taken: 18.05 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 18.05 seconds.\n",
      "2024-05-13 23:03:00,115 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:03:00,115 - micro - MainProcess - INFO     Succesful Run - Time taken: 20.15 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 20.15 seconds.\n",
      "2024-05-13 23:03:00,929 - micro - MainProcess - INFO     CPU usage: 15.5% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 15.5%\n",
      "2024-05-13 23:03:00,981 - micro - MainProcess - INFO     RAM usage: 86.6% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 86.6%\n",
      "2024-05-13 23:03:01,232 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700\n",
      "2024-05-13 23:03:01,232 - micro - MainProcess - INFO     CPU usage: 22.9% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 22.9%\n",
      "2024-05-13 23:03:01,248 - micro - MainProcess - INFO     RAM usage: 86.6% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 86.6%\n",
      "2024-05-13 23:03:01,432 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800\n",
      "2024-05-13 23:03:04,436 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:03:04,436 - micro - MainProcess - INFO     Succesful Run - Time taken: 14.48 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 14.48 seconds.\n",
      "2024-05-13 23:03:05,451 - micro - MainProcess - INFO     CPU usage: 16.1% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 16.1%\n",
      "2024-05-13 23:03:05,481 - micro - MainProcess - INFO     RAM usage: 86.8% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 86.8%\n",
      "2024-05-13 23:03:06,009 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500\n",
      "2024-05-13 23:03:19,159 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:03:19,165 - micro - MainProcess - INFO     Succesful Run - Time taken: 17.80 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 17.80 seconds.\n",
      "2024-05-13 23:03:20,174 - micro - MainProcess - INFO     CPU usage: 19.3% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 19.3%\n",
      "2024-05-13 23:03:20,193 - micro - MainProcess - INFO     RAM usage: 86.7% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 86.7%\n",
      "2024-05-13 23:03:20,637 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700\n",
      "2024-05-13 23:03:21,298 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:03:21,298 - micro - MainProcess - INFO     Succesful Run - Time taken: 15.15 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 15.15 seconds.\n",
      "2024-05-13 23:03:21,500 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:03:21,516 - micro - MainProcess - INFO     Succesful Run - Time taken: 19.94 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 19.94 seconds.\n",
      "2024-05-13 23:03:22,300 - micro - MainProcess - INFO     CPU usage: 21.9% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 21.9%\n",
      "2024-05-13 23:03:22,316 - micro - MainProcess - INFO     RAM usage: 86.7% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 86.7%\n",
      "2024-05-13 23:03:22,524 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500\n",
      "2024-05-13 23:03:22,531 - micro - MainProcess - INFO     CPU usage: 14.1% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 14.1%\n",
      "2024-05-13 23:03:22,557 - micro - MainProcess - INFO     RAM usage: 86.7% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 86.7%\n",
      "2024-05-13 23:03:23,052 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800\n",
      "2024-05-13 23:03:37,044 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:03:37,048 - micro - MainProcess - INFO     Succesful Run - Time taken: 14.38 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 14.38 seconds.\n",
      "2024-05-13 23:03:38,050 - micro - MainProcess - INFO     CPU usage: 15.9% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 15.9%\n",
      "2024-05-13 23:03:38,067 - micro - MainProcess - INFO     RAM usage: 86.3% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 86.3%\n",
      "2024-05-13 23:03:38,289 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500\n",
      "2024-05-13 23:03:39,738 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:03:39,738 - micro - MainProcess - INFO     Succesful Run - Time taken: 18.97 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 18.97 seconds.\n",
      "2024-05-13 23:03:40,763 - micro - MainProcess - INFO     CPU usage: 14.0% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 14.0%\n",
      "2024-05-13 23:03:40,776 - micro - MainProcess - INFO     RAM usage: 87.9% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 87.9%\n",
      "2024-05-13 23:03:41,145 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700\n",
      "2024-05-13 23:03:42,228 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:03:42,231 - micro - MainProcess - INFO     Succesful Run - Time taken: 19.05 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 19.05 seconds.\n",
      "2024-05-13 23:03:43,244 - micro - MainProcess - INFO     CPU usage: 19.9% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 19.9%\n",
      "2024-05-13 23:03:43,260 - micro - MainProcess - INFO     RAM usage: 86.5% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 86.5%\n",
      "2024-05-13 23:03:43,495 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800\n",
      "2024-05-13 23:03:52,365 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:03:52,378 - micro - MainProcess - INFO     Succesful Run - Time taken: 13.95 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 13.95 seconds.\n",
      "2024-05-13 23:03:53,385 - micro - MainProcess - INFO     CPU usage: 12.2% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 12.2%\n",
      "2024-05-13 23:03:53,401 - micro - MainProcess - INFO     RAM usage: 86.7% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 86.7%\n",
      "2024-05-13 23:03:53,644 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500\n",
      "2024-05-13 23:03:58,185 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:03:58,185 - micro - MainProcess - INFO     Succesful Run - Time taken: 16.91 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 16.91 seconds.\n",
      "2024-05-13 23:03:59,200 - micro - MainProcess - INFO     CPU usage: 14.2% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 14.2%\n",
      "2024-05-13 23:03:59,216 - micro - MainProcess - INFO     RAM usage: 86.7% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 86.7%\n",
      "2024-05-13 23:03:59,408 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700\n",
      "2024-05-13 23:04:02,903 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:04:02,914 - micro - MainProcess - INFO     Succesful Run - Time taken: 19.28 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 19.28 seconds.\n",
      "2024-05-13 23:04:03,934 - micro - MainProcess - INFO     CPU usage: 13.6% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 13.6%\n",
      "2024-05-13 23:04:03,958 - micro - MainProcess - INFO     RAM usage: 86.7% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 86.7%\n",
      "2024-05-13 23:04:05,682 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800\n",
      "2024-05-13 23:04:07,848 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:04:07,860 - micro - MainProcess - INFO     Succesful Run - Time taken: 14.07 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 14.07 seconds.\n",
      "2024-05-13 23:04:08,869 - micro - MainProcess - INFO     CPU usage: 16.3% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 16.3%\n",
      "2024-05-13 23:04:08,881 - micro - MainProcess - INFO     RAM usage: 87.4% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 87.4%\n",
      "2024-05-13 23:04:09,735 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500\n",
      "2024-05-13 23:04:18,542 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:04:18,547 - micro - MainProcess - INFO     Succesful Run - Time taken: 19.00 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 19.00 seconds.\n",
      "2024-05-13 23:04:19,567 - micro - MainProcess - INFO     CPU usage: 22.3% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 22.3%\n",
      "2024-05-13 23:04:19,580 - micro - MainProcess - INFO     RAM usage: 87.7% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 87.7%\n",
      "2024-05-13 23:04:19,698 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700\n",
      "2024-05-13 23:04:24,013 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:04:24,016 - micro - MainProcess - INFO     Succesful Run - Time taken: 13.81 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 13.81 seconds.\n",
      "2024-05-13 23:04:25,034 - micro - MainProcess - INFO     CPU usage: 11.2% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 11.2%\n",
      "2024-05-13 23:04:25,047 - micro - MainProcess - INFO     RAM usage: 87.3% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 87.3%\n",
      "2024-05-13 23:04:25,187 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500\n",
      "2024-05-13 23:04:25,605 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:04:25,612 - micro - MainProcess - INFO     Succesful Run - Time taken: 19.79 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 19.79 seconds.\n",
      "2024-05-13 23:04:26,624 - micro - MainProcess - INFO     CPU usage: 27.3% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 27.3%\n",
      "2024-05-13 23:04:26,637 - micro - MainProcess - INFO     RAM usage: 91.1% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 91.1%\n",
      "2024-05-13 23:04:26,860 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800\n",
      "2024-05-13 23:04:37,894 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:04:37,897 - micro - MainProcess - INFO     Succesful Run - Time taken: 18.07 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 18.07 seconds.\n",
      "2024-05-13 23:04:38,916 - micro - MainProcess - INFO     CPU usage: 15.4% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 15.4%\n",
      "2024-05-13 23:04:38,930 - micro - MainProcess - INFO     RAM usage: 89.0% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.0%\n",
      "2024-05-13 23:04:39,047 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700\n",
      "2024-05-13 23:04:39,255 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:04:39,258 - micro - MainProcess - INFO     Succesful Run - Time taken: 13.94 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 13.94 seconds.\n",
      "2024-05-13 23:04:40,252 - micro - MainProcess - INFO     CPU usage: 14.9% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 14.9%\n",
      "2024-05-13 23:04:40,267 - micro - MainProcess - INFO     RAM usage: 88.8% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 88.8%\n",
      "2024-05-13 23:04:40,387 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500\n",
      "2024-05-13 23:04:48,878 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:04:48,883 - micro - MainProcess - INFO     Succesful Run - Time taken: 21.88 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 21.88 seconds.\n",
      "2024-05-13 23:04:49,900 - micro - MainProcess - INFO     CPU usage: 10.1% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 10.1%\n",
      "2024-05-13 23:04:49,915 - micro - MainProcess - INFO     RAM usage: 88.9% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 88.9%\n",
      "2024-05-13 23:04:50,040 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800\n",
      "2024-05-13 23:04:54,332 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:04:54,335 - micro - MainProcess - INFO     Succesful Run - Time taken: 13.81 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 13.81 seconds.\n",
      "2024-05-13 23:04:55,347 - micro - MainProcess - INFO     CPU usage: 13.6% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 13.6%\n",
      "2024-05-13 23:04:55,366 - micro - MainProcess - INFO     RAM usage: 89.8% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.8%\n",
      "2024-05-13 23:04:55,490 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500\n",
      "2024-05-13 23:05:00,348 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:05:00,351 - micro - MainProcess - INFO     Succesful Run - Time taken: 21.16 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 21.16 seconds.\n",
      "2024-05-13 23:05:01,357 - micro - MainProcess - INFO     CPU usage: 16.8% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 16.8%\n",
      "2024-05-13 23:05:01,371 - micro - MainProcess - INFO     RAM usage: 89.4% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.4%\n",
      "2024-05-13 23:05:01,490 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700\n",
      "2024-05-13 23:05:07,255 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:05:07,268 - micro - MainProcess - INFO     Succesful Run - Time taken: 17.09 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 17.09 seconds.\n",
      "2024-05-13 23:05:08,282 - micro - MainProcess - INFO     CPU usage: 20.9% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 20.9%\n",
      "2024-05-13 23:05:08,299 - micro - MainProcess - INFO     RAM usage: 91.2% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 91.2%\n",
      "2024-05-13 23:05:08,483 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800\n",
      "2024-05-13 23:05:09,457 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:05:09,462 - micro - MainProcess - INFO     Succesful Run - Time taken: 13.84 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 13.84 seconds.\n",
      "2024-05-13 23:05:10,484 - micro - MainProcess - INFO     CPU usage: 22.5% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 22.5%\n",
      "2024-05-13 23:05:10,503 - micro - MainProcess - INFO     RAM usage: 91.3% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 91.3%\n",
      "2024-05-13 23:05:10,682 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 500\n",
      "2024-05-13 23:05:21,399 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:05:21,399 - micro - MainProcess - INFO     Succesful Run - Time taken: 19.78 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 19.78 seconds.\n",
      "2024-05-13 23:05:22,433 - micro - MainProcess - INFO     CPU usage: 31.4% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 31.4%\n",
      "2024-05-13 23:05:22,452 - micro - MainProcess - INFO     RAM usage: 94.6% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 94.6%\n",
      "2024-05-13 23:05:22,622 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700\n",
      "2024-05-13 23:05:25,038 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:05:25,041 - micro - MainProcess - INFO     Succesful Run - Time taken: 14.22 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 14.22 seconds.\n",
      "2024-05-13 23:05:26,998 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:05:27,006 - micro - MainProcess - INFO     Succesful Run - Time taken: 18.38 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 18.38 seconds.\n",
      "2024-05-13 23:05:28,015 - micro - MainProcess - INFO     CPU usage: 22.4% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 22.4%\n",
      "2024-05-13 23:05:28,050 - micro - MainProcess - INFO     RAM usage: 90.7% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 90.7%\n",
      "2024-05-13 23:05:28,875 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800\n",
      "2024-05-13 23:05:42,365 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:05:42,370 - micro - MainProcess - INFO     Succesful Run - Time taken: 19.42 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 19.42 seconds.\n",
      "2024-05-13 23:05:43,375 - micro - MainProcess - INFO     CPU usage: 15.7% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 15.7%\n",
      "2024-05-13 23:05:43,383 - micro - MainProcess - INFO     RAM usage: 90.7% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 90.7%\n",
      "2024-05-13 23:05:43,600 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700\n",
      "2024-05-13 23:05:50,322 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:05:50,326 - micro - MainProcess - INFO     Succesful Run - Time taken: 21.32 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 21.32 seconds.\n",
      "2024-05-13 23:05:51,336 - micro - MainProcess - INFO     CPU usage: 16.1% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 16.1%\n",
      "2024-05-13 23:05:51,415 - micro - MainProcess - INFO     RAM usage: 89.9% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.9%\n",
      "2024-05-13 23:05:52,465 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800\n",
      "2024-05-13 23:06:03,569 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:06:03,571 - micro - MainProcess - INFO     Succesful Run - Time taken: 19.84 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 19.84 seconds.\n",
      "2024-05-13 23:06:04,583 - micro - MainProcess - INFO     CPU usage: 14.3% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 14.3%\n",
      "2024-05-13 23:06:04,601 - micro - MainProcess - INFO     RAM usage: 93.1% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 93.1%\n",
      "2024-05-13 23:06:04,852 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700\n",
      "2024-05-13 23:06:11,403 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:06:11,407 - micro - MainProcess - INFO     Succesful Run - Time taken: 18.77 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 18.77 seconds.\n",
      "2024-05-13 23:06:12,422 - micro - MainProcess - INFO     CPU usage: 22.6% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 22.6%\n",
      "2024-05-13 23:06:12,448 - micro - MainProcess - INFO     RAM usage: 89.9% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.9%\n",
      "2024-05-13 23:06:12,654 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800\n",
      "2024-05-13 23:06:22,728 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:06:22,732 - micro - MainProcess - INFO     Succesful Run - Time taken: 17.73 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 17.73 seconds.\n",
      "2024-05-13 23:06:23,732 - micro - MainProcess - INFO     CPU usage: 17.2% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 17.2%\n",
      "2024-05-13 23:06:23,751 - micro - MainProcess - INFO     RAM usage: 90.5% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 90.5%\n",
      "2024-05-13 23:06:23,952 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700\n",
      "2024-05-13 23:06:29,309 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:06:29,619 - micro - MainProcess - INFO     Succesful Run - Time taken: 16.47 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 16.47 seconds.\n",
      "2024-05-13 23:06:30,636 - micro - MainProcess - INFO     CPU usage: 16.9% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 16.9%\n",
      "2024-05-13 23:06:30,656 - micro - MainProcess - INFO     RAM usage: 90.2% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 90.2%\n",
      "2024-05-13 23:06:30,845 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800\n",
      "2024-05-13 23:06:42,933 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:06:43,052 - micro - MainProcess - INFO     Succesful Run - Time taken: 18.79 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 18.79 seconds.\n",
      "2024-05-13 23:06:44,082 - micro - MainProcess - INFO     CPU usage: 18.4% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 18.4%\n",
      "2024-05-13 23:06:44,102 - micro - MainProcess - INFO     RAM usage: 90.6% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 90.6%\n",
      "2024-05-13 23:06:44,380 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700\n",
      "2024-05-13 23:06:48,604 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:06:48,607 - micro - MainProcess - INFO     Succesful Run - Time taken: 17.63 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 17.63 seconds.\n",
      "2024-05-13 23:06:49,616 - micro - MainProcess - INFO     CPU usage: 17.8% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 17.8%\n",
      "2024-05-13 23:06:49,631 - micro - MainProcess - INFO     RAM usage: 91.7% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 91.7%\n",
      "2024-05-13 23:06:49,807 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800\n",
      "2024-05-13 23:07:03,590 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:07:03,596 - micro - MainProcess - INFO     Succesful Run - Time taken: 19.08 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 19.08 seconds.\n",
      "2024-05-13 23:07:04,616 - micro - MainProcess - INFO     CPU usage: 17.2% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 17.2%\n",
      "2024-05-13 23:07:04,633 - micro - MainProcess - INFO     RAM usage: 90.4% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 90.4%\n",
      "2024-05-13 23:07:04,839 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 700\n",
      "2024-05-13 23:07:08,569 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:07:08,574 - micro - MainProcess - INFO     Succesful Run - Time taken: 18.63 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 18.63 seconds.\n",
      "2024-05-13 23:07:09,652 - micro - MainProcess - INFO     CPU usage: 17.9% (utils.py:log_system_info:200)\n",
      "INFO:micro:CPU usage: 17.9%\n",
      "2024-05-13 23:07:09,883 - micro - MainProcess - INFO     RAM usage: 89.6% (utils.py:log_system_info:202)\n",
      "INFO:micro:RAM usage: 89.6%\n",
      "2024-05-13 23:07:10,577 - micro - MainProcess - INFO     Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800 (latencytest.py:make_call:514)\n",
      "INFO:micro:Initiating call for Model: gpt-4-0613-ptu, Max Tokens: 800\n",
      "2024-05-13 23:07:24,429 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:07:24,435 - micro - MainProcess - INFO     Succesful Run - Time taken: 19.46 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 19.46 seconds.\n",
      "2024-05-13 23:07:29,621 - micro - MainProcess - WARNING  x-ratelimit-remaining-tokens is None in headers (utils.py:extract_rate_limit_and_usage_info_async:67)\n",
      "WARNING:micro:x-ratelimit-remaining-tokens is None in headers\n",
      "2024-05-13 23:07:29,626 - micro - MainProcess - INFO     Succesful Run - Time taken: 18.91 seconds. (latencytest.py:make_call:536)\n",
      "INFO:micro:Succesful Run - Time taken: 18.91 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the benchmarking class\n",
    "client_non_streaming = AzureOpenAIBenchmarkNonStreaming(\n",
    "    api_key=OAZURE_OPENAI_API_KEY, azure_endpoint=AZURE_OPENAI_ENDPOINT, api_version=AZURE_OPENAI_API_VERSION\n",
    ")\n",
    "\n",
    "# Run the benchmark tests\n",
    "await client_non_streaming.run_latency_benchmark_bulk(\n",
    "    deployment_names, max_tokens_list, iterations=num_iterations, context_tokens=1000, multiregion=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+----------------+--------------------+---------------------+----------------------+----------------------+----------------------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|  Model_MaxTokens   | Iterations |    Regions     |    Median Time     |      IQR Time       | 95th Percentile Time | 99th Percentile Time |       CV Time        | Median Prompt Tokens | IQR Prompt Tokens | Median Completion Tokens | IQR Completion Tokens | 95th Percentile Completion Tokens | 99th Percentile Completion Tokens | CV Completion Tokens | Error Rate | Error Types | Successful Runs | Unsuccessful Runs | Throttle Count |                                                                                   Best Run                                                                                   |                                                                                  Worst Run                                                                                   |\n",
      "+--------------------+------------+----------------+--------------------+---------------------+----------------------+----------------------+----------------------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| gpt-4-0613-ptu_100 |     25     | Sweden Central | 3.559292793273926  | 0.21331048011779785 |  4.145424318313598   |  4.698113813400267   | 0.08040529572996019  |        1005.0        |        2.0        |          100.0           |          0.0          |               100.0               |               100.0               |         0.0          |    0.0     |     []      |       25        |         0         |       0        | {\"time\": 3.4698944091796875, \"completion_tokens\": 100, \"prompt_tokens\": 1005, \"region\": \"Sweden Central\", \"utilization\": \"13.52%\", \"local_time\": \"2024-05-14 05:59:24 CEST\"} |  {\"time\": 4.858916521072388, \"completion_tokens\": 100, \"prompt_tokens\": 1006, \"region\": \"Sweden Central\", \"utilization\": \"9.54%\", \"local_time\": \"2024-05-14 05:59:01 CEST\"}  |\n",
      "| gpt-4-0613-ptu_500 |     25     | Sweden Central | 14.150249481201172 | 0.5243489742279053  |  15.371616744995118  |  16.279442720413204  | 0.044754927276807646 |        1005.0        |        1.0        |          500.0           |          0.0          |               500.0               |               500.0               |         0.0          |    0.0     |     []      |       25        |         0         |       0        | {\"time\": 13.796731233596802, \"completion_tokens\": 500, \"prompt_tokens\": 1006, \"region\": \"Sweden Central\", \"utilization\": \"57.45%\", \"local_time\": \"2024-05-14 06:01:12 CEST\"} | {\"time\": 16.554846048355103, \"completion_tokens\": 500, \"prompt_tokens\": 1004, \"region\": \"Sweden Central\", \"utilization\": \"36.75%\", \"local_time\": \"2024-05-14 06:02:32 CEST\"} |\n",
      "| gpt-4-0613-ptu_700 |     25     | Sweden Central | 19.08210301399231  | 0.9979069232940674  |  21.802304029464718  |  21.99098108291626   | 0.062172004075484816 |        1005.0        |        2.0        |          666.0           |         54.0          |               700.0               |               700.0               | 0.04604999091348258  |    0.0     |     []      |       25        |         0         |       0        | {\"time\": 16.90897011756897, \"completion_tokens\": 604, \"prompt_tokens\": 1006, \"region\": \"Sweden Central\", \"utilization\": \"20.38%\", \"local_time\": \"2024-05-14 06:03:58 CEST\"}  | {\"time\": 22.000213146209717, \"completion_tokens\": 631, \"prompt_tokens\": 1004, \"region\": \"Sweden Central\", \"utilization\": \"56.83%\", \"local_time\": \"2024-05-14 06:01:19 CEST\"} |\n",
      "| gpt-4-0613-ptu_800 |     25     | Sweden Central | 19.282745838165283 | 1.7725958824157715  |  21.768435430526733  |  22.02436156272888   | 0.08128769668897463  |        1005.0        |        2.0        |          667.0           |         67.0          |         735.1999999999999         |         773.9599999999999         | 0.07223077243195329  |    0.0     |     []      |       25        |         0         |       0        | {\"time\": 15.34395956993103, \"completion_tokens\": 555, \"prompt_tokens\": 1005, \"region\": \"Sweden Central\", \"utilization\": \"45.82%\", \"local_time\": \"2024-05-14 06:01:08 CEST\"}  | {\"time\": 22.06951594352722, \"completion_tokens\": 785, \"prompt_tokens\": 1004, \"region\": \"Sweden Central\", \"utilization\": \"46.73%\", \"local_time\": \"2024-05-14 06:01:54 CEST\"}  |\n",
      "+--------------------+------------+----------------+--------------------+---------------------+----------------------+----------------------+----------------------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "stats = client_non_streaming.calculate_and_show_statistics()\n",
    "now = datetime.now()\n",
    "timestamp = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "latency_file_name = FILENAME + f\"latency/results_iterations={num_iterations}_time={timestamp}.json\"\n",
    "client_non_streaming.save_statistics_to_file(stats, location=latency_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Throughput Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Create a custom logger\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set the level of this logger. This level acts as a threshold.\n",
    "# Any message logged at this level, or higher, will be passed to this logger's handlers.\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Create handlers\n",
    "c_handler = logging.StreamHandler()\n",
    "c_handler.setLevel(logging.DEBUG)\n",
    "c_format = logging.Formatter(\"%(name)s - %(levelname)s - %(message)s\")\n",
    "c_handler.setFormatter(c_format)\n",
    "logger.addHandler(c_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.performance.client import LoadTestBenchmarking\n",
    "\n",
    "# Create a client\n",
    "benchmarking_client = LoadTestBenchmarking(\n",
    "    model=MODEL,\n",
    "    region=REGION,\n",
    "    endpoint=AZURE_OPENAI_ENDPOINT,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- `CLIENTS (10)`: This parameter sets the number of concurrent clients that will be generating load.\n",
    "\n",
    "- `RATE (13)`: This parameter defines the rate of request generation in Requests Per Minute (RPM). \n",
    "\n",
    "- `DURATION (180)`: This parameter specifies the duration of the load test in seconds. A value of 180 seconds means the load test will run for 3 minutes.\n",
    "\n",
    "- `MAX_TOKENS (500)`: When the `SHAPE_PROFILE` is set to \"custom\", this parameter defines the maximum number of tokens that can be generated in each response from the API. A value of 500 tokens allows for detailed responses.\n",
    "\n",
    "- `CONTEXT_TOKENS (1000)`: Also used when the `SHAPE_PROFILE` is \"custom\", this parameter sets the number of tokens that will be used as context for each request to the API. A value of 1000 tokens provides a rich context for generating responses.\n",
    "\n",
    "- `SHAPE_PROFILE (\"custom\")`: This parameter determines the shape profile of requests. A \"custom\" value means the number of context tokens and max tokens will be determined by the `CONTEXT_TOKENS` and `MAX_TOKENS` parameters respectively.\n",
    "\n",
    "- `PREVENT_SERVER_CACHING (True)`: When set to True, this parameter ensures each request is processed independently by the server, without any influence from previous requests. It does this by adding random prefixes to all requests, preventing server-side caching.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENTS = 10 \n",
    "RATE = 43\n",
    "DURATION=180\n",
    "MAX_TOKENS=500\n",
    "CONTEXT_TOKENS=1000\n",
    "SHAPE_PROFILE = \"custom\"\n",
    "PREVENT_SERVER_CACHING = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 23:43:45,122 - micro - MainProcess - INFO     Initiating load generation tests with ID f963. Log output will be directed to: benchmarks/gpt4/swedencentral/gpt-4-0613-ptu/throughput/clients=10_rate=43_time=20240513_234345.json (client.py:run_tests:243)\n",
      "INFO:micro:Initiating load generation tests with ID f963. Log output will be directed to: benchmarks/gpt4/swedencentral/gpt-4-0613-ptu/throughput/clients=10_rate=43_time=20240513_234345.json\n",
      "2024-05-13 23:43:45,126 - micro - MainProcess - INFO     Executing command: python -m src.performance.bench load --api-version 2024-02-15-preview --api-key-env OPENAI_API_KEY_SWEEDENCENTRAL_GPT4_PTU --clients 10 --duration 180 --run-end-condition-mode or --rate 43 --aggregation-window 60 --context-generation-method generate --shape-profile custom --context-tokens 1000 --max-tokens 500 --prevent-server-caching True --completions 1 --output-format human --log-save-dir logs/ --retry none --deployment gpt-4-0613-ptu https://gbb-ea-openai-swedencentral-02.openai.azure.com/ (client.py:run_tests:246)\n",
      "INFO:micro:Executing command: python -m src.performance.bench load --api-version 2024-02-15-preview --api-key-env OPENAI_API_KEY_SWEEDENCENTRAL_GPT4_PTU --clients 10 --duration 180 --run-end-condition-mode or --rate 43 --aggregation-window 60 --context-generation-method generate --shape-profile custom --context-tokens 1000 --max-tokens 500 --prevent-server-caching True --completions 1 --output-format human --log-save-dir logs/ --retry none --deployment gpt-4-0613-ptu https://gbb-ea-openai-swedencentral-02.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "timestamp = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "benchmarking_client.run_tests(\n",
    "    api_version=AZURE_OPENAI_API_VERSION,\n",
    "    api_key_env=\"OPENAI_API_KEY_SWEEDENCENTRAL_GPT4_PTU\",\n",
    "    deployment=MODEL,\n",
    "    rate=RATE,\n",
    "    duration=DURATION,\n",
    "    shape_profile=SHAPE_PROFILE,\n",
    "    clients=CLIENTS,\n",
    "    context_tokens=CONTEXT_TOKENS,\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    prevent_server_caching=PREVENT_SERVER_CACHING,\n",
    "    log_file_path=FILENAME + f\"throughput/clients={CLIENTS}_rate={RATE}_time={timestamp}.json\",\n",
    "\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptu-benchmarking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
